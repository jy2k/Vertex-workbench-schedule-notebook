{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3ab7921-a2d2-47bd-91c3-8a7dec41af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfd9b9-c13b-4b84-b05e-a6690ed72e9d",
   "metadata": {},
   "source": [
    "### Check the version of the framework you are using because the pre built container used for batch prediction needs to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3a75ed-4ac8-4f30-9117-2d1f0ebdc58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.0.2.\n"
     ]
    }
   ],
   "source": [
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c966fddc-50f7-4cfe-8a53-73a3f7d8df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris(as_frame=True)\n",
    "iris_data.data.to_csv(\"iris.csv\")\n",
    "data = iris_data.data\n",
    "labels = iris_data.target\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05529d32-3c7f-4df4-b20f-161afb88c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c001d0d6-f891-444c-96c9-36726d698976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ecf79cf-3235-46c1-96bf-49c24f0b5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d20366-6500-4ca7-b573-3c9603b9733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
       "                ('gbtrees', GradientBoostingClassifier())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    \n",
    "    # Scaler\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    \n",
    "    # Classifier\n",
    "    ('gbtrees', GradientBoostingClassifier())\n",
    "\n",
    "])\n",
    "clf.fit(X=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94f3f55-50c3-4243-a7d0-8310f14598cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model train accuracy:1.0\n",
      "Model test accuracy:0.9\n"
     ]
    }
   ],
   "source": [
    "print(f'Model train accuracy:{accuracy_score(y_train, clf.predict(x_train))}')\n",
    "print(f'Model test accuracy:{accuracy_score(y_test, clf.predict(x_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28fa4755-4aa6-4b8a-ad54-879cbb668093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Getting the current date and time\n",
    "TIMESTAMP = str(datetime.now())\n",
    "BUCKET_NAME = \"automl-output-mlops\"\n",
    "FILENAME = \"demo_etl.pkl\"\n",
    "LOCATION = \"us-central1\"\n",
    "#pre-built containers\n",
    "DOCKER_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\" # https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "#TODO: change to actual project\n",
    "PROJECT_ID = \"mlops-demos-306914\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a43b454-35fc-4b41-b50f-7665bd72235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(FILENAME, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4da1272-954e-4f35-bfcc-c5727338ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(FILENAME, 'rb'))\n",
    "result = loaded_model.score(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb09b263-fb9a-4d6a-bae6-9eb6f44d6006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.google.com/storage/docs/uploading-objects\n",
    "from google.cloud import storage\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    \n",
    "upload_blob(bucket_name=BUCKET_NAME, source_file_name=FILENAME, destination_blob_name=FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83cd99a2-80e7-4b59-835a-48788217d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/983707479002/locations/us-central1/models/2574119448344526848/operations/9190294672642146304\n",
      "Model created. Resource name: projects/983707479002/locations/us-central1/models/2574119448344526848@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/983707479002/locations/us-central1/models/2574119448344526848@1')\n",
      "2022-09-14 07:23:28.394969\n",
      "projects/983707479002/locations/us-central1/models/2574119448344526848\n"
     ]
    }
   ],
   "source": [
    "#https://cloud.google.com/vertex-ai/docs/model-registry/import-model#pre-built-container\n",
    "#https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/upload_model_sample.py\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "#TODO: change display name\n",
    "model = aiplatform.Model.upload(\n",
    "        display_name=TIMESTAMP,\n",
    "        artifact_uri=\"gs://\"+BUCKET_NAME+\"/\",\n",
    "        serving_container_image_uri=DOCKER_IMAGE_URI,\n",
    "        sync=True)\n",
    "\n",
    "model.wait()\n",
    "\n",
    "print(model.display_name)\n",
    "print(model.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bdc85a-a4f2-44c0-b53a-66b649be9891",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> Problem:</span>\n",
    "## <span style=\"color:orange\">Batch_predict job hangs. runs for 40 minutes and then fails with the following message: </span>\n",
    "## <span style=\"color:orange\">Error: model server never became ready. Please validate that your model file or container configuration are valid.</span>\n",
    "## <span style=\"color:blue\">The sci kit version used to train the model 1.0.2 </span>\n",
    "## <span style=\"color:blue\">pre built prediction container version is 1.0</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcba180d-78d1-4d36-bfcd-bc14dd67ecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/466455988333969408?project=983707479002\n",
      "BatchPredictionJob projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/983707479002/locations/us-central1/batchPredictionJobs/466455988333969408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1/3822414961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mgcs_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gs://automl-output-mlops/iris.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgcs_destination_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gs://automl-output-mlops/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         machine_type = \"n1-standard-2\")\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mbatch_predict\u001b[0;34m(self, job_display_name, gcs_source, bigquery_source, instances_format, gcs_destination_prefix, bigquery_destination_prefix, predictions_format, model_parameters, machine_type, accelerator_type, accelerator_count, starting_replica_count, max_replica_count, generate_explanation, explanation_metadata, explanation_parameters, labels, credentials, encryption_spec_key_name, sync, create_request_timeout, batch_size)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0mencryption_spec_key_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencryption_spec_key_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m             \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3625\u001b[0m         )\n\u001b[1;32m   3626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, job_display_name, model_name, instances_format, predictions_format, gcs_source, bigquery_source, gcs_destination_prefix, bigquery_destination_prefix, model_parameters, machine_type, accelerator_type, accelerator_count, starting_replica_count, max_replica_count, generate_explanation, explanation_metadata, explanation_parameters, labels, project, location, credentials, encryption_spec_key_name, sync, create_request_timeout, batch_size)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mgenerate_explanation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_explanation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         )\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, empty_batch_prediction_job, model_or_model_name, gca_batch_prediction_job, generate_explanation, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    776\u001b[0m         )\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_prediction_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0mlog_wait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_wait\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_WAIT_TIME_MULTIPLIER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MAX_WAIT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mprevious_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_JOB_WAIT_TIME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_job_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#https://github.com/googleapis/python-aiplatform/blob/2bc9b2b0d048c29ba43c8b4c3ea51370515d08c3/samples/model-builder/create_batch_prediction_job_sample.py\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "#No need to re-init but I wanted the cells to be standalone\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "my_model = aiplatform.Model(model.resource_name)\n",
    "#TODO: I pre uploaded the CSV to a bucket. Alternatively this can be done on the fly\n",
    "#TODO: Remove test2\n",
    "batch_prediction_job = my_model.batch_predict(\n",
    "        job_display_name=TIMESTAMP,\n",
    "        gcs_source=\"gs://automl-output-mlops/iris.csv\",\n",
    "        gcs_destination_prefix=\"gs://automl-output-mlops/\",\n",
    "        machine_type = \"n1-standard-2\")\n",
    "\n",
    "batch_prediction_job.wait()\n",
    "\n",
    "print(batch_prediction_job.display_name)\n",
    "print(batch_prediction_job.resource_name)\n",
    "print(batch_prediction_job.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9b75c-e462-4a75-9bde-7cace504bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download CSV from bucket\n",
    "#Write to database X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
